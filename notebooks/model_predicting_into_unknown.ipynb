{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get database connection parameters from environment variables\n",
    "db_name = os.getenv('DB_NAME')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "\n",
    "# Create the database URL\n",
    "db_url = f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "\n",
    "# Create an engine\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Define your query -> set your table name here\n",
    "query = 'SELECT * FROM \"03_gold\".\"fact_electricity_market_germany\"'\n",
    "\n",
    "# Execute the query and load the data into a pandas DataFrame\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get forecast data\n",
    "# Define your query\n",
    "query3 = 'SELECT * FROM \"02_silver\".\"fact_full_weather\"'\n",
    "\n",
    "# Execute the query and load the data into a pandas DataFrame\n",
    "forecasts = pd.read_sql(query3, engine).sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time variables\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['dayofweek'] = df['timestamp'].dt.dayofweek\n",
    "df['quarter'] = df['timestamp'].dt.quarter\n",
    "df['month'] = df['timestamp'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create splits for expanding window crossvalidation\n",
    "# Parameters\n",
    "n_splits = 23 # our data has 23 quarters = (len(X) / 2190)\n",
    "train_increment = 2190  # Number of hours in a quarter year\n",
    "test_size = 72 # we currently want to predict for 72 hours. Can be adjusted.\n",
    "\n",
    "class CustomTimeSeriesSplit:\n",
    "    def __init__(self, n_splits, train_increment, test_size):\n",
    "        self.n_splits = n_splits\n",
    "        self.train_increment = train_increment\n",
    "        self.test_size = test_size\n",
    "\n",
    "    def split(self, X):\n",
    "        n_samples = len(X)\n",
    "        indices = np.arange(n_samples)\n",
    "        splits = []\n",
    "        \n",
    "        for i in range(self.n_splits):\n",
    "            train_end = (i + 1) * self.train_increment\n",
    "            test_end = train_end + self.test_size\n",
    "            \n",
    "            if test_end > n_samples:\n",
    "                break\n",
    "\n",
    "            train_index = indices[:train_end]\n",
    "            test_index = indices[train_end:test_end]\n",
    "            splits.append((train_index, test_index))\n",
    "        \n",
    "        return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the custom splits\n",
    "custom_splitter = CustomTimeSeriesSplit(n_splits=n_splits, train_increment=train_increment, test_size=test_size)\n",
    "splits = custom_splitter.split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_features(df, target_column, lagged_vars):\n",
    "    for lag in lagged_vars:\n",
    "        df[f'{target_column}_{lag}_lag'] = df[target_column].shift(lag)\n",
    "        df[f'{target_column}_{lag}_mean'] = df[target_column].shift(1).rolling(lag).mean()\n",
    "        df[f'{target_column}_{lag}_std'] = df[target_column].shift(1).rolling(lag).std()\n",
    "        df[f'{target_column}_{lag}_max'] = df[target_column].shift(1).rolling(lag).max()\n",
    "        df[f'{target_column}_{lag}_min'] = df[target_column].shift(1).rolling(lag).min()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_time_series_model_sliding(df, known_vars, target_column, model_class, model_params=None, train_size=2190, test_size=72):\n",
    "    if model_params is None:\n",
    "        model_params = {}\n",
    "\n",
    "    mae_scores = []\n",
    "    plot_data = []\n",
    "    mse_score_sum = []\n",
    "\n",
    "    lagged_vars = [6, 12, 24, 48, 72]\n",
    "\n",
    "    # Define sliding window split\n",
    "    for split_start in range(0, len(df) - train_size - test_size + 1, train_size):\n",
    "        train_start = split_start\n",
    "        train_end = split_start + train_size\n",
    "        test_start = train_end\n",
    "        test_end = train_end + test_size\n",
    "\n",
    "        train_data = df.iloc[train_start:train_end].copy()\n",
    "        test_data = df.iloc[test_start:test_end].copy()\n",
    "\n",
    "        # Combine last 72 hours of training data with test data for lagged feature creation\n",
    "        combined_data = pd.concat([train_data.iloc[-72:], test_data])\n",
    "        \n",
    "        # Create lagged features for training data\n",
    "        train_data = create_lagged_features(train_data, target_column, lagged_vars).dropna()\n",
    "                \n",
    "        known_features_train = train_data[known_vars + [f'{target_column}_{lag}_lag' for lag in lagged_vars] + \\\n",
    "                                            [f'{target_column}_{lag}_mean' for lag in lagged_vars] + \\\n",
    "                                            [f'{target_column}_{lag}_std' for lag in lagged_vars] + \\\n",
    "                                            [f'{target_column}_{lag}_max' for lag in lagged_vars] + \\\n",
    "                                            [f'{target_column}_{lag}_min' for lag in lagged_vars]].dropna()\n",
    "        target_train = train_data[target_column]\n",
    "        \n",
    "        # Train the model\n",
    "        model = model_class(**model_params)\n",
    "        model.fit(known_features_train, target_train)\n",
    "\n",
    "        # Initialize the dataset with known values of y\n",
    "        known_data = combined_data.iloc[:72].copy()\n",
    "\n",
    "        # Predict the test data\n",
    "        predictions = []\n",
    "        \n",
    "        \n",
    "        # Iterate over the rows where we need to predict y (from 73rd to 144th row)\n",
    "        for i in range(72, len(combined_data)):\n",
    "            # Append the predicted value of y from the previous step to known_data\n",
    "            if i > 72:\n",
    "                for var in known_vars:\n",
    "                    known_data[var] = pd.concat([known_data[var], pd.Series([predictions[-1]])], ignore_index=True)\n",
    "\n",
    "            # Create lagged features based on the current known_data\n",
    "            known_data_with_lags = create_lagged_features(combined_data, target_column, lagged_vars).dropna()\n",
    "            # Check if there are enough rows to predict\n",
    "            if i >= 144:\n",
    "                break\n",
    "            # Prepare predictors for the current row\n",
    "            predictors = known_data_with_lags.iloc[-1][known_vars + \\\n",
    "                                               [f'{target_column}_{lag}_lag' for lag in lagged_vars] + \\\n",
    "                                               [f'{target_column}_{lag}_mean' for lag in lagged_vars] + \\\n",
    "                                               [f'{target_column}_{lag}_std' for lag in lagged_vars] + \\\n",
    "                                               [f'{target_column}_{lag}_max' for lag in lagged_vars] + \\\n",
    "                                               [f'{target_column}_{lag}_min' for lag in lagged_vars]].values.reshape(1, -1)\n",
    "            print(predictors)\n",
    "            prediction = model.predict(predictors)[0]\n",
    "            predictions.append(prediction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # # Create lagged features for the test data up to the current point\n",
    "            # if i == 0:\n",
    "            #     test_data_with_lags = create_lagged_features(test_data.copy(), target_column, lagged_vars)\n",
    "            # else:\n",
    "            #     test_data_with_lags.loc[test_data.index[i], target_column] = predictions[-1]\n",
    "            #     test_data_with_lags = create_lagged_features(test_data_with_lags, target_column, lagged_vars)\n",
    "\n",
    "            # # Ensure no NaN values exist after creating lagged features\n",
    "            # test_data_with_lags.dropna(inplace=True)\n",
    "            # # Check if there are enough rows to predict\n",
    "            # if i >= len(test_data_with_lags):\n",
    "            #     break\n",
    "            \n",
    "            # known_features_test = test_data_with_lags[known_vars + [f'{target_column}_{lag}_lag' for lag in lagged_vars] + \\\n",
    "            #                                 [f'{target_column}_{lag}_mean' for lag in lagged_vars] + \\\n",
    "            #                                 [f'{target_column}_{lag}_std' for lag in lagged_vars] + \\\n",
    "            #                                 [f'{target_column}_{lag}_max' for lag in lagged_vars] + \\\n",
    "            #                                 [f'{target_column}_{lag}_min' for lag in lagged_vars]].iloc[i].values.reshape(1, -1)\n",
    "            # predictions.append(model.predict(known_features_test)[0])\n",
    "\n",
    "        # Calculate MAE for the current split\n",
    "        actual = test_data[target_column][:test_size].values\n",
    "        mae = mean_absolute_error(actual, predictions)\n",
    "        mae_scores.append(mae)\n",
    "        print(f\"Split {split_start // test_size + 1}: MAE = {mae}\")\n",
    "\n",
    "        # Calculate MSE for plotting\n",
    "        mse_train = mean_squared_error(target_train, model.predict(known_features_train))\n",
    "        mse_test = mean_squared_error(actual, predictions)\n",
    "\n",
    "        mse_score_sum.append({'split': split_start // test_size + 1, 'Type': 'Train', 'MSE': mse_train})\n",
    "        mse_score_sum.append({'split': split_start // test_size + 1, 'Type': 'Test', 'MSE': mse_test})\n",
    "\n",
    "        plot_data.append({\n",
    "            'split': split_start // test_size + 1,\n",
    "            'y_train': target_train,\n",
    "            'y_pred_train': model.predict(known_features_train),\n",
    "            'y_test': actual,\n",
    "            'y_pred_test': predictions\n",
    "        })\n",
    "\n",
    "    average_mae = np.mean(mae_scores)\n",
    "    print(f\"Average MAE across all splits: {average_mae}\")\n",
    "\n",
    "    mse_score_sum = pd.DataFrame(mse_score_sum)\n",
    "\n",
    "    return average_mae, plot_data, mse_score_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'known_data_with_lags' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m average_mae, plot_data, mse_score_sum \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_time_series_model_sliding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mExtraTreesRegressor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[64], line 48\u001b[0m, in \u001b[0;36mevaluate_time_series_model_sliding\u001b[1;34m(df, known_vars, target_column, model_class, model_params, train_size, test_size)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m72\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# For the first prediction, no previous predictions exist\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m72\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m         predictors \u001b[38;5;241m=\u001b[39m \u001b[43mknown_data_with_lags\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][known_vars \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     49\u001b[0m                                        [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_lag\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m lagged_vars] \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     50\u001b[0m                                        [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mean\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m lagged_vars] \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     51\u001b[0m                                        [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_std\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m lagged_vars] \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     52\u001b[0m                                        [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_max\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m lagged_vars] \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     53\u001b[0m                                        [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_min\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m lagged_vars]]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;66;03m# Append the predicted value of y from the previous step to known_data\u001b[39;00m\n\u001b[0;32m     56\u001b[0m         known_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([known_data, pd\u001b[38;5;241m.\u001b[39mDataFrame({var: [predictions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m df\u001b[38;5;241m.\u001b[39miloc[i][var]] \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns})], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'known_data_with_lags' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "average_mae, plot_data, mse_score_sum = evaluate_time_series_model_sliding(\n",
    "    df, known_vars, target_column, ExtraTreesRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_time_series_model_sliding(df, known_vars, target_column, model_class, model_params=None, train_size=2190, test_size=72):\n",
    "    if model_params is None:\n",
    "        model_params = {}\n",
    "\n",
    "    mae_scores = []\n",
    "    plot_data = []\n",
    "    mse_score_sum = []\n",
    "\n",
    "    lagged_vars = [6, 12, 24, 48, 72]\n",
    "\n",
    "    # Define sliding window split\n",
    "    for split_start in range(0, len(df) - train_size - test_size + 1, train_size):\n",
    "        train_start = split_start\n",
    "        train_end = split_start + train_size\n",
    "        test_start = train_end\n",
    "        test_end = train_end + test_size\n",
    "\n",
    "        train_data = df.iloc[train_start:train_end].copy()\n",
    "        test_data = df.iloc[test_start:test_end].copy()\n",
    "\n",
    "        # Combine last 72 hours of training data with test data for lagged feature creation\n",
    "        combined_data = pd.concat([train_data.iloc[-72:], test_data])\n",
    "        \n",
    "        # Create lagged features for training data\n",
    "        train_data = create_lagged_features(train_data, target_column, lagged_vars).dropna()\n",
    "                \n",
    "        known_features_train = train_data[known_vars + [f'{target_column}_{lag}_lag' for lag in lagged_vars] + \\\n",
    "                                            [f'{target_column}_{lag}_mean' for lag in lagged_vars] + \\\n",
    "                                            [f'{target_column}_{lag}_std' for lag in lagged_vars] + \\\n",
    "                                            [f'{target_column}_{lag}_max' for lag in lagged_vars] + \\\n",
    "                                            [f'{target_column}_{lag}_min' for lag in lagged_vars]].dropna()\n",
    "        target_train = train_data[target_column]\n",
    "        \n",
    "        # Train the model\n",
    "        model = model_class(**model_params)\n",
    "        model.fit(known_features_train, target_train)\n",
    "\n",
    "        # Initialize the dataset with known values of y\n",
    "        known_data = combined_data.iloc[:72].copy()\n",
    "\n",
    "        \n",
    "        \n",
    "        # Predict the test data\n",
    "        predictions = []\n",
    "                \n",
    "        # Iterate over the rows where we need to predict y (from 73rd to 144th row)\n",
    "        for i in range(72, len(combined_data)):\n",
    "            # Append the predicted value of y from the previous step to known_data\n",
    "            if i > 72:\n",
    "                for var in known_vars:\n",
    "                    known_data[var] = pd.concat([known_data[var], pd.Series([predictions[-1]])], ignore_index=True)\n",
    "\n",
    "            # Create lagged features based on the current known_data\n",
    "            known_data_with_lags = create_lagged_features(combined_data, target_column, lagged_vars).dropna()\n",
    "            # Check if there are enough rows to predict\n",
    "            if i >= 144:\n",
    "                break\n",
    "            # Prepare predictors for the current row\n",
    "            predictors = known_data_with_lags.iloc[-1][known_vars + \\\n",
    "                                               [f'{target_column}_{lag}_lag' for lag in lagged_vars] + \\\n",
    "                                               [f'{target_column}_{lag}_mean' for lag in lagged_vars] + \\\n",
    "                                               [f'{target_column}_{lag}_std' for lag in lagged_vars] + \\\n",
    "                                               [f'{target_column}_{lag}_max' for lag in lagged_vars] + \\\n",
    "                                               [f'{target_column}_{lag}_min' for lag in lagged_vars]].values.reshape(1, -1)\n",
    "            print(predictors)\n",
    "            prediction = model.predict(predictors)[0]\n",
    "            predictions.append(prediction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # # Create lagged features for the test data up to the current point\n",
    "            # if i == 0:\n",
    "            #     test_data_with_lags = create_lagged_features(test_data.copy(), target_column, lagged_vars)\n",
    "            # else:\n",
    "            #     test_data_with_lags.loc[test_data.index[i], target_column] = predictions[-1]\n",
    "            #     test_data_with_lags = create_lagged_features(test_data_with_lags, target_column, lagged_vars)\n",
    "\n",
    "            # # Ensure no NaN values exist after creating lagged features\n",
    "            # test_data_with_lags.dropna(inplace=True)\n",
    "            # # Check if there are enough rows to predict\n",
    "            # if i >= len(test_data_with_lags):\n",
    "            #     break\n",
    "            \n",
    "            # known_features_test = test_data_with_lags[known_vars + [f'{target_column}_{lag}_lag' for lag in lagged_vars] + \\\n",
    "            #                                 [f'{target_column}_{lag}_mean' for lag in lagged_vars] + \\\n",
    "            #                                 [f'{target_column}_{lag}_std' for lag in lagged_vars] + \\\n",
    "            #                                 [f'{target_column}_{lag}_max' for lag in lagged_vars] + \\\n",
    "            #                                 [f'{target_column}_{lag}_min' for lag in lagged_vars]].iloc[i].values.reshape(1, -1)\n",
    "            # predictions.append(model.predict(known_features_test)[0])\n",
    "\n",
    "        # Calculate MAE for the current split\n",
    "        actual = test_data[target_column][:test_size].values\n",
    "        mae = mean_absolute_error(actual, predictions)\n",
    "        mae_scores.append(mae)\n",
    "        print(f\"Split {split_start // test_size + 1}: MAE = {mae}\")\n",
    "\n",
    "        # Calculate MSE for plotting\n",
    "        mse_train = mean_squared_error(target_train, model.predict(known_features_train))\n",
    "        mse_test = mean_squared_error(actual, predictions)\n",
    "\n",
    "        mse_score_sum.append({'split': split_start // test_size + 1, 'Type': 'Train', 'MSE': mse_train})\n",
    "        mse_score_sum.append({'split': split_start // test_size + 1, 'Type': 'Test', 'MSE': mse_test})\n",
    "\n",
    "        plot_data.append({\n",
    "            'split': split_start // test_size + 1,\n",
    "            'y_train': target_train,\n",
    "            'y_pred_train': model.predict(known_features_train),\n",
    "            'y_test': actual,\n",
    "            'y_pred_test': predictions\n",
    "        })\n",
    "\n",
    "    average_mae = np.mean(mae_scores)\n",
    "    print(f\"Average MAE across all splits: {average_mae}\")\n",
    "\n",
    "    mse_score_sum = pd.DataFrame(mse_score_sum)\n",
    "\n",
    "    return average_mae, plot_data, mse_score_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(plot_data, mse_score_sum, model_name='', only_bar=True):\n",
    "    \"\"\"\n",
    "    Plot the time series data stored in plot_data.\n",
    "\n",
    "    Parameters:\n",
    "    - plot_data: list of dictionaries containing data for plotting\n",
    "    - mse_score_sum: DataFrame containing MSE scores for each split and type (Train/Test)\n",
    "    - only_bar: if False, Time Series Plots will created for each split. Default = True.\n",
    "    \"\"\"\n",
    "\n",
    "    if not only_bar:\n",
    "        for data in plot_data:\n",
    "            split = data['split']\n",
    "            y_train = data['y_train']\n",
    "            y_pred_train = data['y_pred_train']\n",
    "            y_test = data['y_test']\n",
    "            y_pred_test = data['y_pred_test']\n",
    "\n",
    "            # Plotting Full Time Series\n",
    "            plt.figure()\n",
    "            sns.lineplot(x=y_train.index, y=y_train, label='Actual train')\n",
    "            sns.lineplot(x=y_train.index, y=y_pred_train, label='Predicted train', linestyle='--')\n",
    "            sns.lineplot(x=y_test.index, y=y_test, label='Actual test')\n",
    "            sns.lineplot(x=y_test.index, y=y_pred_test, label='Predicted test', linestyle='--')\n",
    "            plt.title(f'Actual vs Predicted for Split {split}')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Target')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            # Plotting Zoomed Time Series\n",
    "            plt.figure()\n",
    "            sns.lineplot(x=y_train.index[-168:], y=y_train[-168:], label='Actual train')\n",
    "            sns.lineplot(x=y_train.index[-168:], y=y_pred_train[-168:], label='Predicted train', linestyle='--')\n",
    "            sns.lineplot(x=y_test.index, y=y_test, label='Actual test')\n",
    "            sns.lineplot(x=y_test.index, y=y_pred_test, label='Predicted test', linestyle='--')\n",
    "            plt.title(f'Zoomed: Actual vs Predicted for Split {split}')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Target')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    # Plot using seaborn\n",
    "    if model_name:\n",
    "        model_name = f'{model_name}: '\n",
    "    plt.figure()\n",
    "    sns.barplot(x='split', y='MSE', hue='Type', data=mse_score_sum)\n",
    "    plt.title(f'{model_name}Comparison of MSE for Training and Test Sets')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.xlabel('Split')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_vars = ['temperature_2m', 'relative_humidity_2m', 'apparent_temperature', 'precipitation', 'cloud_cover', 'wind_speed_10m', 'wind_direction_10m',\n",
    "            'direct_radiation', 'diffuse_radiation', 'sunshine_duration', 'hour', 'dayofweek', 'quarter', 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'price_eur_mwh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows where y is known initially\n",
    "initial_known_rows = 72\n",
    "\n",
    "# Lagged variables for y\n",
    "lagged_vars = [6, 12, 24, 48, 72]\n",
    "\n",
    "# Function to create lagged features for y\n",
    "def create_lagged_features(df, target_column, lagged_vars):\n",
    "    for lag in lagged_vars:\n",
    "        df[f'{target_column}_{lag}_lag'] = df[target_column].shift(lag)\n",
    "        df[f'{target_column}_{lag}_mean'] = df[target_column].shift(1).rolling(lag).mean()\n",
    "        df[f'{target_column}_{lag}_std'] = df[target_column].shift(1).rolling(lag).std()\n",
    "        df[f'{target_column}_{lag}_max'] = df[target_column].shift(1).rolling(lag).max()\n",
    "        df[f'{target_column}_{lag}_min'] = df[target_column].shift(1).rolling(lag).min()\n",
    "    return df\n",
    "\n",
    "# Initialize the dataset with known values of y\n",
    "known_data = df.iloc[:initial_known_rows].copy()\n",
    "\n",
    "# Initialize predictions list to store predicted values of y\n",
    "predictions = []\n",
    "\n",
    "# Fit the model initially with known data\n",
    "known_data_with_lags = create_lagged_features(known_data.copy(), 'y', lagged_vars).dropna()\n",
    "model = ExtraTreesRegressor()  # Example model\n",
    "model.fit(known_data_with_lags[['known_var1', 'known_var2'] + \\\n",
    "                               [f'y_{lag}_lag' for lag in lagged_vars] + \\\n",
    "                               [f'y_{lag}_mean' for lag in lagged_vars] + \\\n",
    "                               [f'y_{lag}_std' for lag in lagged_vars] + \\\n",
    "                               [f'y_{lag}_max' for lag in lagged_vars] + \\\n",
    "                               [f'y_{lag}_min' for lag in lagged_vars]], \n",
    "          known_data_with_lags['y'])\n",
    "\n",
    "# Iterate over the rows where we need to predict y (from 73rd to 144th row)\n",
    "for i in range(initial_known_rows, len(df)):\n",
    "    # For the first prediction, no previous predictions exist\n",
    "    if i == initial_known_rows:\n",
    "        predictors = known_data_with_lags.iloc[-1][['known_var1', 'known_var2'] + \\\n",
    "                                                   [f'y_{lag}_lag' for lag in lagged_vars] + \\\n",
    "                                                   [f'y_{lag}_mean' for lag in lagged_vars] + \\\n",
    "                                                   [f'y_{lag}_std' for lag in lagged_vars] + \\\n",
    "                                                   [f'y_{lag}_max' for lag in lagged_vars] + \\\n",
    "                                                   [f'y_{lag}_min' for lag in lagged_vars]].values.reshape(1, -1)\n",
    "    else:\n",
    "        # Append the predicted value of y from the previous step to known_data\n",
    "        known_data = pd.concat([known_data, pd.DataFrame({var: [predictions[-1] if var == 'y' else df.iloc[i][var]] for var in df.columns})], ignore_index=True)\n",
    "\n",
    "        # Create lagged features based on the current known_data\n",
    "        known_data_with_lags = create_lagged_features(known_data.copy(), 'y', lagged_vars).dropna()\n",
    "\n",
    "        # Prepare predictors for the current row\n",
    "        predictors = known_data_with_lags.iloc[-1][['known_var1', 'known_var2'] + \\\n",
    "                                                   [f'y_{lag}_lag' for lag in lagged_vars] + \\\n",
    "                                                   [f'y_{lag}_mean' for lag in lagged_vars] + \\\n",
    "                                                   [f'y_{lag}_std' for lag in lagged_vars] + \\\n",
    "                                                   [f'y_{lag}_max' for lag in lagged_vars] + \\\n",
    "                                                   [f'y_{lag}_min' for lag in lagged_vars]].values.reshape(1, -1)\n",
    "    \n",
    "    # Example model prediction (you should replace this with your model fitting and prediction logic)\n",
    "    prediction = model.predict(predictors)[0]\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Calculate MAE for the predicted values (from 73rd to 144th row)\n",
    "actual = df.iloc[initial_known_rows:]['y'].values\n",
    "mae = mean_absolute_error(actual, predictions)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
